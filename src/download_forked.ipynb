{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "The field which Study.write_config fills in 'references' is arbitrary. Fix it.\n",
    "\n",
    "When eventually making the script that calls snakemake, make sure to run it with Anaconda3, not 2\n",
    "\n",
    "## Test accession numbers\n",
    "PRJEB2772 Few small files\n",
    "\n",
    "PRJEB1786 Lots of large files\n",
    "\n",
    "PRJEB2773 Not Illumina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the newest version of Download, made to be compatible with my own Snakefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import shutil\n",
    "import argparse\n",
    "import json\n",
    "import subprocess\n",
    "import gzip\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from time import sleep\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Globally count errors and warnings\n",
    "errors = 0\n",
    "warnings = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ENA classes\n",
    "class Entry:\n",
    "    \"\"\"A parent class for ENA entries of any kind.\"\"\"\n",
    "    \n",
    "    def superentry(self, parent, parentdict):\n",
    "        \"\"\"Define the parent entry of the entry and add it to the parentdict\"\"\"\n",
    "        if self.accession in parentdict:\n",
    "            raise ValueError('{} already in {}'.format(self, parent))\n",
    "        \n",
    "        parentdict[self.accession] = self\n",
    "        return parent\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '<{} {} at {}>'.format(\n",
    "            self.__class__.__name__, self.accession, hex(id(self)))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Study(Entry):\n",
    "    \"\"\"An ENA entry corresponding to one study, AKA project.\"\"\"\n",
    "    \n",
    "    def __init__(self, accession):\n",
    "        self.accession = accession\n",
    "        \n",
    "        # Sub-entries\n",
    "        self.samples = {}\n",
    "        self.experiments = {}\n",
    "        self.runs = {}\n",
    "        self.files = {}\n",
    "        \n",
    "    def write_config(self, configpath, log):\n",
    "        \"\"\"Creates a JSON config file for Simon's script.\"\"\"\n",
    "        global errors\n",
    "\n",
    "        samples_to_experiments = {sample.accession: list(sample.experiments)\n",
    "                                 for sample in self.samples.values()}\n",
    "\n",
    "        experiments_to_runs = {experiment.accession: list(experiment.runs)\n",
    "                                 for experiment in self.experiments.values()}\n",
    "\n",
    "        runs_to_files = {run.accession: [file.path for file in \n",
    "                                         run.files.values() if file.downloaded]\n",
    "                                    for run in self.runs.values()}\n",
    "\n",
    "        encodings = set(file.guess_phred_encoding()\n",
    "                        for file in self.files.values())\n",
    "        \n",
    "        if 0 in encodings:\n",
    "            errors += 1\n",
    "            print('Error: Quality encoding for some file(s) in study {} cannot'\n",
    "                  'be determined. Study quality encoding Set to 0'.format(\n",
    "                                                  self.accession), file=log)\n",
    "            encoding = 0\n",
    "        \n",
    "        elif len(encodings) == 1:\n",
    "            encoding = encodings.pop()\n",
    "        \n",
    "        else:\n",
    "            errors += 1\n",
    "            print('Error: Differing quality encodings for study {}. '\n",
    "                  'Set to 0'.format(self.accession), file=log)\n",
    "            encoding = 0\n",
    "        \n",
    "        # Gather dictionaries and print in JSON file.\n",
    "        jsoncontent = OrderedDict((\n",
    "                ('human_reference', 'UNDEFINED'),\n",
    "                ('cores', 4),\n",
    "                ('phred_encoding', encoding),\n",
    "                ('bwa_path', '/services/tools/bwa/0.7.15/bwa'),\n",
    "                ('samtools_path', '/services/tools/bwa/0.7.15/samtools'),\n",
    "                ('megahit_path', '/services/tools/megahit/1.0.4-beta/megahit'),\n",
    "                ('prodigal_path', '/services/tools/prodigal-2.6.2/prodigal'),\n",
    "                ('adapterremoval_path', '/services/tools/adapterremoval/2.2.0/'\n",
    "                                        'bin/AdapterRemoval'),\n",
    "                ('cd-hit_path', '/services/tools/cd-hit-4.6.1/bin/cd-hit-est'),\n",
    "                ('canopy_path', '/home/projects/pr_99009/people/sira/share/'\n",
    "                                'bin/cc.bin'),\n",
    "                ('samples', samples_to_experiments),\n",
    "                ('experiments', experiments_to_runs),\n",
    "                ('runs', runs_to_files)))                \n",
    "\n",
    "        with open(configpath, 'w') as configfile:\n",
    "            print(json.dumps(jsoncontent, indent=4), file=configfile)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sample(Entry):\n",
    "    \"\"\"An ENA entry corresponding to one sample.\"\"\"\n",
    "    \n",
    "    def __init__(self, accession, study):         \n",
    "        self.accession = accession\n",
    "        \n",
    "        # Super-entries\n",
    "        self.study = self.superentry(study, study.samples)\n",
    "        \n",
    "        # Sub-entries\n",
    "        self.experiments = {}\n",
    "        self.runs = {}\n",
    "        self.files = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Experiment(Entry):\n",
    "    \"\"\"An ENA entry corresponding to one experiment, AKA library.\"\"\"\n",
    "    \n",
    "    def __init__(self, accession, sample, platform, library_layout):         \n",
    "        self.accession = accession\n",
    "        self.platform = platform\n",
    "        self.se = library_layout.lower() == 'single'\n",
    "        \n",
    "        # Super-entries\n",
    "        self.sample = self.superentry(sample, sample.experiments)\n",
    "        self.study = self.superentry(sample.study, sample.study.experiments)\n",
    "        \n",
    "        # Sub-entries\n",
    "        self.runs = {}\n",
    "        self.files = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Run(Entry):\n",
    "    \"\"\"An ENA entry corresponding to one run, AKA unit.\"\"\"\n",
    "    \n",
    "    def __init__(self, accession, experiment, ftps, filesizes):\n",
    "        self.accession = accession\n",
    "        \n",
    "        # Super-entries\n",
    "        self.experiment = self.superentry(experiment, experiment.runs) \n",
    "        self.sample = self.superentry(experiment.sample, experiment.sample.runs)\n",
    "        self.study = self.superentry(experiment.study, experiment.study.runs)\n",
    "        \n",
    "        # Sub-entries\n",
    "        self.files = {}\n",
    "        \n",
    "        # Instantiate Files\n",
    "        ftps = ['ftp://' + ftp for ftp in ftps.split(';')]\n",
    "        filesizes = [int(filesize) for filesize in filesizes.split(';')]\n",
    "    \n",
    "        if not (len(ftps) == 1 or (not experiment.se and len(ftps) == 2)):\n",
    "            raise ValueError('Unexpected number of files in run {}.'.format(\n",
    "                                                                accession))\n",
    "        \n",
    "        interleaved = len(ftps) == 1 and not experiment.se\n",
    "        for ftpadress, filesize in zip(ftps, filesizes):\n",
    "            path = os.path.abspath(os.path.join(args.destination, \n",
    "                                                self.study.accession,\n",
    "                                                os.path.basename(ftpadress)))\n",
    "            \n",
    "            File(path, self, ftpadress, filesize, interleaved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class File(Entry):\n",
    "    \"\"\"A gz file. Strictly speaking this is not an ENA entry, but that makes\n",
    "    my code cleaner.\"\"\"\n",
    "    \n",
    "    def __init__(self, path, run, ftpadress, filesize, interleaved):\n",
    "        self.path = path\n",
    "        self.accession = path # to allow superentry method\n",
    "        self.ftpadress = ftpadress\n",
    "        self.filesize = filesize\n",
    "        self.downloaded = False\n",
    "        self.interleaved = interleaved\n",
    "        \n",
    "        # Super-entries\n",
    "        self.run = self.superentry(run, run.files) \n",
    "        self.experiment = self.superentry(run.experiment, run.experiment.files) \n",
    "        self.sample = self.superentry(run.sample, run.sample.files)\n",
    "        self.study = self.superentry(run.study, run.study.files)\n",
    "        \n",
    "    def validate_download(self):\n",
    "        if os.path.getsize(self.path) != self.filesize:\n",
    "            os.remove(self.path)\n",
    "            raise OSError('Size of file {} does not match expected size.'\n",
    "                          'Deleting file.'.format(self.path))\n",
    "\n",
    "        else:\n",
    "            self.downloaded = True\n",
    "    \n",
    "    def split(self, *newpaths):\n",
    "        \"\"\"If the file is split into several new files, update instances.\"\"\"\n",
    "        for path in newpaths:\n",
    "            newfile = File(path, self.run, None, os.path.getsize(path), False)\n",
    "            newfile.downloaded = True\n",
    "        self.run.files.pop(self.accession)\n",
    "        \n",
    "    def guess_phred_encoding(self):\n",
    "        \"\"\"Guess the PHRED encoding (33 or 64) from the first 100 lines.\"\"\"\n",
    "        \n",
    "        with gzip.open(self.path, 'rt') as file:\n",
    "            charset = set()\n",
    "            try:\n",
    "                for read in range(25):\n",
    "                    next(file) # Header\n",
    "                    next(file) # Sequence\n",
    "                    next(file) # +\n",
    "                    charset.update(set(next(file))) # PHRED encoded line\n",
    "\n",
    "            except StopIteration:\n",
    "                return 0\n",
    "\n",
    "        low = any(ch in charset for ch in \"\"\"!\"#$%&'()*+,-./0123456789\"\"\")\n",
    "        high = any(ch in charset for ch in \"\"\"KLMNOPQRSTUVWXYZ[\\]^_`abcdefg\"\"\")\n",
    "\n",
    "        if low and not high:\n",
    "            return 33\n",
    "        elif high and not low:\n",
    "            return 64\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def download(self, disable_deinterleave):\n",
    "        \"\"\"Downloads a file given the data from a File.\"\"\"\n",
    "        # This function is to be executed in parallel child processes.\n",
    "        # Therefore, it only has access to copies of objects.\n",
    "        # So no direct modifying of objects in this function.\n",
    "\n",
    "        if os.path.exists(self.path):\n",
    "            if self.filesize == os.path.getsize(self.path):\n",
    "                return None\n",
    "            else:\n",
    "                raise FileExistsError('File already exist, '\n",
    "                                'but its size differs from metadata file size.'\n",
    "\n",
    "        with urllib.request.urlopen(\n",
    "            self.ftpadress, timeout=30) as infile, open(self.path, 'wb') as outfile:\n",
    "            shutil.copyfileobj(infile, outfile)\n",
    "\n",
    "        # Deinterleave if appropriate\n",
    "        if self.interleaved and not disable_deinterleave:\n",
    "            forward, reverse = self.path[:-3]+'_1.gz', self.path[:-3]+'_2.gz'\n",
    "            if os.path.exists(forward) or os.path.exists(reverse):\n",
    "                raise FileExistsError('Cannot disinterleave {}, '\n",
    "                        'file with same name and _1 or _2 suffix'\n",
    "                        'already exist'.format(self.path))\n",
    "\n",
    "            # Deinterleave bash command derived from Nathan Watson-Haigh's work.\n",
    "            command = (r'gunzip -c {} | paste - - - - - - - - | tee >('\n",
    "                       r'cut -f 1-4 | tr \"\\t\" \"\\n\" | gzip > {}) | '\n",
    "                       r'cut -f 5-8 | tr \"\\t\" \"\\n\" | gzip > {}').format(\n",
    "                self.path, forward, reverse)\n",
    "\n",
    "\n",
    "            process = subprocess.Popen(command, shell=True,\n",
    "                                       executable='/bin/bash')\n",
    "            process.wait() # Unbelievably, this is required.\n",
    "\n",
    "            if process.poll() == 0: # Error code returned, 0 means no error\n",
    "                os.remove(self.path)\n",
    "                return forward, reverse\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "    \"\"\"Makes a directory at the given path.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "\n",
    "    except FileExistsError:\n",
    "        if not os.path.isdir(path):\n",
    "            raise FileExistsError('Non-directory file already exists at: '\n",
    "                                  '{}'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_entries(accession):\n",
    "    \"\"\"Given a study accession returns a generator of tuples:\n",
    "(study_accession, sample_accession, experiment_accession, run_accession,\n",
    "platform, library_layout, fastq_ftp, fastqbytes, submitted_ftp, submbytes).\n",
    "\"\"\"\n",
    "    \n",
    "    url = ('http://www.ebi.ac.uk/ena/data/warehouse/filereport?accession={}'\n",
    "          '&result=read_run&fields='\n",
    "          'study_accession,sample_accession,experiment_accession,run_accession,'\n",
    "          'instrument_platform,library_layout,fastq_ftp,fastq_bytes,'\n",
    "          'submitted_ftp,submitted_bytes'.format(accession))\n",
    "    \n",
    "    with urllib.request.urlopen(url) as lines:\n",
    "        rowgenerator = (line.decode().rstrip('\\n').split('\\t')\n",
    "                        for line in lines)\n",
    "        next(rowgenerator) # iterate past header line\n",
    "    \n",
    "        return list(rowgenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_entries(accession_list, log):\n",
    "    \"\"\"Chains together multiple entries from accessions. If one fails to load,\n",
    "prints error to log instead of raising an exception.\"\"\"\n",
    "    \n",
    "    global errors\n",
    "    \n",
    "    for accession in set(accession_list): # Remove duplicates\n",
    "        try:\n",
    "            for entry in download_entries(accession):\n",
    "                yield entry\n",
    "        \n",
    "        except urllib.error.HTTPError:\n",
    "            print('Unable to fetch data from server for accession ID {}. '\n",
    "                  'Is it right?'.format(accession), file=log)\n",
    "            errors += 1\n",
    "            \n",
    "        except urllib.error.URLError:\n",
    "            print('Unable to connect to server to fetch data for study {}. '\n",
    "                  'Check internet connection.'.format(accession), file=log)\n",
    "            errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_metadata(entrygenerator, log):\n",
    "    \"\"\"Writes the content of the entries to the log\"\"\"\n",
    "    \n",
    "    columnnames = ('study', 'sample', 'experiment', 'run', 'platform', 'layout',\n",
    "              'ftps', 'filesizes')\n",
    "    print('\\t'.join(columnnames), file=log)\n",
    "    \n",
    "    for line in entrygenerator:\n",
    "        print('\\t'.join(line), file=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def instantiate_from_entries(entries, log):\n",
    "    \"\"\"Given an iterable of entries, instantiates all the included ENA entries.\"\"\"\n",
    "    # Does not instantiate files, as they do not constitute an entry.\n",
    "    # Instead, initialization of a Run instantiates its associated files.\n",
    "    \n",
    "    global errors\n",
    "    \n",
    "    studies = {}\n",
    "    \n",
    "    for (studyacc, sampleacc, expacc, runacc, instr, layout,\n",
    "             fastqftps, fastqsizes, submittedftps, submittedsizes) in entries:\n",
    "        \n",
    "        try:\n",
    "            if fastqftps:\n",
    "                ftps, filesizes = fastqftps, fastqsizes\n",
    "            elif 'fastq' in submittedftps:\n",
    "                ftps, filesizes = submittedftps, submittedsizes\n",
    "            else:\n",
    "                raise ValueError('No fastq files found for {}'.format(runacc))\n",
    "            \n",
    "            # Don't use 'study = studies.get(studyacc, Study(studyacc))'\n",
    "            # as Study(studyacc) will be evaluated even if studyacc in studies\n",
    "            study = studies.get(studyacc)\n",
    "            if study is None:\n",
    "                study = Study(studyacc)\n",
    "                studies[studyacc] = study\n",
    "                \n",
    "            sample = study.samples.get(sampleacc)\n",
    "            if sample is None:\n",
    "                sample = Sample(sampleacc, study)\n",
    "                \n",
    "            experiment = sample.experiments.get(expacc)\n",
    "            if experiment is None:\n",
    "                experiment = Experiment(expacc, sample, instr, layout)\n",
    "            \n",
    "            Run(runacc, experiment, ftps, filesizes)\n",
    "                \n",
    "        except Exception as error:\n",
    "            print('Error when instantiating: {}'.format(error), file=log)\n",
    "            errors += 1\n",
    "    \n",
    "    return studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download(studies, log):\n",
    "    \"\"\"Downloads all the files in the given dictionary of studies in parallel\"\"\"\n",
    "    \n",
    "    global errors, warnings\n",
    "\n",
    "    files = set().union(*(study.files.values() for study in studies.values()))\n",
    "\n",
    "    if not args.quiet:\n",
    "        print('Found {} files, total size: {} GB. '\n",
    "              'Downloading asynchronously...'.format(len(files), \n",
    "                        round(sum(file.filesize for file in files)/1e9, 3)))\n",
    "    \n",
    "    fileno, filestotal = 1, len(files)\n",
    "    \n",
    "    def callback(message):\n",
    "        nonlocal fileno, filestotal\n",
    "        if not args.quiet:\n",
    "            end = '\\n' if fileno == filestotal else '\\r'\n",
    "            print('    {}/{} processed...'.format(fileno, filestotal), end=end)\n",
    "        fileno += 1\n",
    "\n",
    "    pool = Pool(processes=args.cores)\n",
    "    returns = []\n",
    "    for file in files:\n",
    "        if not os.path.exists(file.path):\n",
    "            sleep(10) # Avoid overloading servers\n",
    "            \n",
    "        returns.append((file, pool.apply_async(file.download, (args.letleave,),\n",
    "                                                callback=callback,\n",
    "                                                error_callback=callback)))\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    # Process returns from child processes\n",
    "    for file, returnvalue in returns:\n",
    "        try:\n",
    "            deinterleaved = returnvalue.get()\n",
    "            \n",
    "        except Exception as error:\n",
    "                print('Error when downloading {}: {}'.format(\n",
    "                    file.path, error), file=log)\n",
    "                errors += 1\n",
    "        else:\n",
    "            if deinterleaved: # Deinterleaved is fw, rv pair\n",
    "                file.split(*deinterleaved)\n",
    "                print('File {} automatically deinterleaved.'.format(file),\n",
    "                      file=log)\n",
    "                \n",
    "            else: # If deinterleaves is None or False\n",
    "                try:\n",
    "                    file.validate_download()\n",
    "                except OSError as error:\n",
    "                    print('Error {}'.format(error), file=log)\n",
    "                    errors += 1\n",
    "                finally:\n",
    "                    if deinterleaved is False:\n",
    "                        print('Attempted automatic deinterleaving of {}, '\n",
    "                              'but it failed.'.format(file), file=log)\n",
    "                        errors += 1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(accessions):\n",
    "    \"\"\"Executes the main script.\"\"\"\n",
    "    \n",
    "    global errors, warnings\n",
    "    \n",
    "    mkdir(args.destination)\n",
    "            \n",
    "    logpath = os.path.join(args.destination, 'download.log')\n",
    "    logexists = os.path.exists(logpath)\n",
    "    with open(logpath, 'a') as log:\n",
    "        if logexists:\n",
    "            print('\\n\\nNew run:', file=log)\n",
    "    \n",
    "        entries = generate_entries(accessions, log)\n",
    "        \n",
    "        if args.metadata:\n",
    "            write_metadata(entries, log)\n",
    "            if not args.quiet:\n",
    "                print('Added metadata to log file')\n",
    "            return\n",
    "        \n",
    "        studies = instantiate_from_entries(entries, log)\n",
    "        \n",
    "        for accession in studies:\n",
    "            mkdir(os.path.join(args.destination, accession))\n",
    "                \n",
    "        download(studies, log)\n",
    "    \n",
    "        if args.config:\n",
    "            for study in studies.values():\n",
    "                path = os.path.join(args.destination, study.accession,\n",
    "                                    'config.json')\n",
    "                study.write_config(path, log)\n",
    "            if not args.quiet:\n",
    "                print('Made JSON config files. Check their values.')\n",
    "    \n",
    "    if not args.quiet and not (warnings or errors):\n",
    "        print('Done.')\n",
    "    \n",
    "    elif not args.quiet:\n",
    "        message = 'Completed with {} warnings and {} errors. Check log file.'\n",
    "        print(message.format(warnings, errors))\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        description=\"\"\"Automatic ENA file downloader.\n",
    "Given a list of ENA study accessions, does the following:\n",
    "\n",
    "- Downloads metadata from the ENA accession IDs.\n",
    "- Downloads all the associated fastq files and saves them in a directory.\n",
    "- If metadata suggests paired end, but only one file is seen, deinterleaves.\n",
    "- Optionally generates a configfile for use with Simon's metagenomic pipeline\n",
    "\n",
    "Created by Jakob Nybo Nissen, jakni@dtu.dk, 2016-12-13\n",
    "PLEASE CONTACT ME WITH BUGS AND REQUESTS!\n",
    "\"\"\")\n",
    "    \n",
    "    parser.add_argument('destination', type=str,\n",
    "        help='Destination directory')\n",
    "    \n",
    "    parser.add_argument('accessions', type=str, nargs='+',\n",
    "        help='ENA accession ID(s) to download from')\n",
    "    \n",
    "    parser.add_argument('-c', type=int, default=1, dest='cores',\n",
    "        help='No. of cores to use [1].')\n",
    "    \n",
    "    parser.add_argument('--quiet', action='store_true',\n",
    "        help = 'Suppress non-error outputs.')\n",
    "    \n",
    "    parser.add_argument('--metadata', action='store_true',\n",
    "        help = 'Only write metadata to log, do not download files.')\n",
    "    \n",
    "    parser.add_argument('--config', action='store_true',\n",
    "        help = 'Make config files.')\n",
    "    \n",
    "    parser.add_argument('--letleave', action='store_true',\n",
    "        help = 'Disable automatic deinterleaving.')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if type(args.cores) != int or args.cores < 1:\n",
    "        print('Zero or negative cores provided. Exiting')\n",
    "    \n",
    "    elif args.metadata and args.config:\n",
    "        print('Cannot produce configuration files from only metadata. '\n",
    "             'Choose either --metadata or --config. Exiting.')\n",
    "        \n",
    "    else:\n",
    "        if not args.letleave:\n",
    "            if os.name != 'posix':\n",
    "                args.letleave = True\n",
    "                print('Non-UNIX operating system found. Deinterleaving disabled.')\n",
    "            \n",
    "            if not os.path.isfile('/bin/bash'):\n",
    "                args.letleave = True\n",
    "                print('/bin/bash not detected. Deinterleaving disabled.')\n",
    "    \n",
    "        main(args.accessions)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    class A:\n",
    "        def __init__(self):\n",
    "            self.destination = 'deletemedir'\n",
    "            self.config = True\n",
    "            self.cores = 4\n",
    "            self.metadata = False\n",
    "            self.quiet = False\n",
    "            self.letleave = False\n",
    "\n",
    "    args = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if debug:\n",
    "    with open('deletemelog' ,'a') as log:\n",
    "        #main(['PRJEB2772'])\n",
    "        print(list(generate_entries(['PRJEB2772'], log)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
