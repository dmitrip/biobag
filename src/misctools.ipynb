{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bioinformatics toolbox\\n\\nThis is a loose collection of tools for tasks that the author have had to do\\ntoo many times, e.g. parsing and translating a Fasta file.\\n\\nAuthor: Jakob Nybo Nissen, DTU Bioinformatics\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Bioinformatics toolbox\n",
    "\n",
    "This is a loose collection of tools for tasks that the author have had to do\n",
    "too many times, e.g. parsing and translating a Fasta file.\n",
    "\n",
    "Author: Jakob Nybo Nissen, DTU Bioinformatics\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections as _collections\n",
    "import gzip as _gzip\n",
    "from misctools_c import reverse_complement_kmer\n",
    "from misctools_c import kmercounts as _kmercounts\n",
    "from misctools_c import threemerfreq as _threemerfreq\n",
    "from misctools_c import fourmerfreq as _fourmerfreq\n",
    "from misctools_c import freq_432mers as _freq_432mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reader:\n",
    "    \"Use this instead of `open` for files which may be gzipped or not.\"\n",
    "    \n",
    "    def __init__(self, filename, readmode='r'):\n",
    "        if readmode not in ('r', 'rb'):\n",
    "            raise ValueError(\"the reader cannot write, set mode to 'r' or 'rb'\")\n",
    "        \n",
    "        self.filename = filename\n",
    "        self.readmode = readmode\n",
    "    \n",
    "    def __enter__(self):\n",
    "        with open(self.filename, 'rb') as f:\n",
    "            signature = f.peek(2)[:2]\n",
    "        \n",
    "        # Gzipped files begin with the two bytes 1F8B\n",
    "        if tuple(signature) == (31, 139):\n",
    "            if self.readmode == 'r':\n",
    "                self.filehandle = _gzip.open(self.filename, 'rt')\n",
    "                \n",
    "            else:\n",
    "                self.filehandle = _gzip.open(self.filename, self.readmode)\n",
    "                \n",
    "        else:\n",
    "            self.filehandle = open(self.filename, self.readmode)\n",
    "            \n",
    "        return self.filehandle\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.filehandle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streamprint(iterator, filehandle, bufferlength=10000, sep='\\n'):\n",
    "    \"\"\"Given an iterator of lines and a filehandle, prints the content of the\n",
    "    iterator to the file in a memory-efficient way.\n",
    "    \n",
    "    Return the number of iterator-given strings processed.\"\"\"\n",
    "    \n",
    "    buffer = list()\n",
    "    operations = 0\n",
    "    \n",
    "    for thing in iterator:      \n",
    "        buffer.append(str(thing))\n",
    "        \n",
    "        if len(buffer) == bufferlength:\n",
    "            print(sep.join(buffer), file=filehandle, end=sep)\n",
    "            operations += bufferlength\n",
    "            buffer.clear()\n",
    "    \n",
    "    print(sep.join(buffer), file=filehandle, end=sep)\n",
    "    return operations + len(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forkprint(iterator, *filenames, bufferlength=100, sep='\\n'):\n",
    "    \"\"\"Given an iterator returning (index, line) and N filenames, prints\n",
    "    the line to the index'th filename memory-efficiently.\n",
    "    \n",
    "    Returns a tuple of the number of printing operations.\n",
    "    \"\"\"\n",
    "    \n",
    "    operations = [0]*len(filenames)\n",
    "    \n",
    "    buffers = list()\n",
    "    for fh in filenames:\n",
    "        buffers.append(list())\n",
    "    \n",
    "    for index, thing in iterator:\n",
    "        buffers[index].append(str(thing))\n",
    "        \n",
    "        if len(buffers[index]) == bufferlength:\n",
    "            with open(filenames[index], 'a') as file:\n",
    "                print(sep.join(buffers[index]), file=file)\n",
    "                \n",
    "            operations[index] += bufferlength\n",
    "            buffers[index].clear()\n",
    "            \n",
    "    for index, (buffer, filename) in enumerate(zip(buffers, filenames)):\n",
    "        if not buffer:\n",
    "            continue\n",
    "            \n",
    "        with open(filename, 'a') as file:\n",
    "            print(sep.join(buffer), file=file)\n",
    "            \n",
    "        operations[index] += len(buffer)\n",
    "        buffer.clear()\n",
    "        \n",
    "    return tuple(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def significant(n, digits=3):\n",
    "    \"\"\"\"Returns a number rounded to some (default 3) significant digits.\n",
    "    \n",
    "    significant(5882) == '5880'\n",
    "    significant(0.40032, 4) == '0.400'\"\"\"\n",
    "    \n",
    "    if digits < 1:\n",
    "        raise ValueError('Digits must be >= 1')\n",
    "    \n",
    "    integer_digits = len(str(int(n))) - (n < 0)\n",
    "    \n",
    "    if integer_digits >= digits:\n",
    "        return str(int(round(n, digits - integer_digits)))\n",
    "    \n",
    "    else:\n",
    "        return ('{' + '0:.{}f'.format(digits - integer_digits) + '}').format(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastaEntry:\n",
    "    \"\"\"One single FASTA entry. The header is immutable, and FastaEntries are\n",
    "    grouped in dicts and sets by their header. Entries are compared equal by\n",
    "    their sequence\n",
    "    \n",
    "    >>> a, b, c = FastaEntry('>one', 'TAG'), FastaEntry('one', 'TAG'), FastaEntry('two', 'CTA')\n",
    "    >>> a.header == c.header, a.header == b.header # \">\" in header removed on instantiation\n",
    "    False, True\n",
    "    >>> a == b == c.reversecomplement() # Entries compared by sequence\n",
    "    True\n",
    "    >>> a is b, set((a, b)) # distinct objects, hashes same\n",
    "    False, {<Fasta Entry one>}\n",
    "    >>> a.translate().sequence, b.translate(endatstop=True)\n",
    "    '*', None\n",
    "    \"\"\"\n",
    "    \n",
    "    __slots__ = ['header', 'sequence']\n",
    "    \n",
    "    genetic_code = {\n",
    "    (65, 65, 65): 75, (65, 65, 71): 75, (65, 65, 84): 78, (65, 65, 67): 78,\n",
    "    (65, 71, 65): 82, (65, 71, 71): 82, (65, 71, 84): 83, (65, 71, 67): 83,\n",
    "    (65, 84, 65): 73, (65, 84, 71): 77, (65, 84, 84): 73, (65, 84, 67): 73,\n",
    "    (65, 67, 65): 84, (65, 67, 71): 84, (65, 67, 84): 84, (65, 67, 67): 84,\n",
    "    (71, 65, 65): 69, (71, 65, 71): 69, (71, 65, 84): 68, (71, 65, 67): 68,\n",
    "    (71, 71, 65): 71, (71, 71, 71): 71, (71, 71, 84): 71, (71, 71, 67): 71,\n",
    "    (71, 84, 65): 86, (71, 84, 71): 86, (71, 84, 84): 86, (71, 84, 67): 86,\n",
    "    (71, 67, 65): 65, (71, 67, 71): 65, (71, 67, 84): 65, (71, 67, 67): 65,\n",
    "    (84, 65, 65): 42, (84, 65, 71): 42, (84, 65, 84): 89, (84, 65, 67): 89,\n",
    "    (84, 71, 65): 42, (84, 71, 71): 87, (84, 71, 84): 67, (84, 71, 67): 67,\n",
    "    (84, 84, 65): 76, (84, 84, 71): 76, (84, 84, 84): 70, (84, 84, 67): 70,\n",
    "    (84, 67, 65): 83, (84, 67, 71): 83, (84, 67, 84): 83, (84, 67, 67): 83,\n",
    "    (67, 65, 65): 81, (67, 65, 71): 81, (67, 65, 84): 72, (67, 65, 67): 72,\n",
    "    (67, 71, 65): 82, (67, 71, 71): 82, (67, 71, 84): 82, (67, 71, 67): 82,\n",
    "    (67, 84, 65): 76, (67, 84, 71): 76, (67, 84, 84): 76, (67, 84, 67): 76,\n",
    "    (67, 67, 65): 80, (67, 67, 71): 80, (67, 67, 84): 80, (67, 67, 67): 80,\n",
    "    }\n",
    "\n",
    "    \n",
    "    dna_alphabet = b'ACGT'\n",
    "    iupacdna_alphabet = b'ACGTMRWSYKVHDBN'\n",
    "    aa_alphabet = b'ACDEFGHIKLMNPQRSTVWY'\n",
    "    rna_alphabet = b'ACGU'\n",
    "    complementtable = bytes.maketrans(b'ACGTMRWSYKVHDBN', b'TGCAKYWSRMBDHVN')\n",
    "    \n",
    "    def __init__(self, header, sequence):\n",
    "        if header[0] in ('>', '#') or header[0].isspace():\n",
    "            raise ValueError('Header cannot begin with #, > or whitespace')\n",
    "        self.header = header\n",
    "            \n",
    "        if isinstance(sequence, bytearray):\n",
    "            self.sequence = sequence\n",
    "        \n",
    "        elif isinstance(sequence, str):\n",
    "            self.sequence = bytearray(sequence.encode())\n",
    "            \n",
    "        elif isinstance(sequence, bytes):\n",
    "            self.sequence = bytearray(sequence)\n",
    "                \n",
    "        else:\n",
    "            raise ValueError('sequence must be str, bytes or bytearray')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequence)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '>{}\\n{}'.format(self.header, self.sequence.decode())\n",
    "    \n",
    "    def format(self, width=60):\n",
    "        sixtymers = range(0, len(self.sequence), width)\n",
    "        spacedseq = '\\n'.join([self.sequence[i: i+width].decode() for i in sixtymers])\n",
    "        return '>{}\\n{}'.format(self.header, spacedseq)\n",
    "    \n",
    "    # Two entries with same header cannot co-exist in same set/dict!\n",
    "    def __hash__(self):\n",
    "        return hash(self.header)\n",
    "    \n",
    "    def __contains__(self, other):\n",
    "        if isinstance(other, str):\n",
    "            return other.encode() in self.sequence\n",
    "        \n",
    "        elif isinstance(other, bytes) or isinstance(other, bytearray):\n",
    "            return other in self.sequence\n",
    "        \n",
    "        else:\n",
    "            raise TypeError('Can only compare to str, bytes or bytearray')\n",
    "    \n",
    "    # Entries are compared equal by their sequence.\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, self.__class__):\n",
    "            return self.sequence == other.sequence\n",
    "        else:\n",
    "            raise TypeError('Cannot compare to object of other class')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.sequence[index]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return '<FastaEntry {}>'.format(self.header)\n",
    "    \n",
    "    def reversecomplemented(self):\n",
    "        stripped = self.sequence.translate(None, delete=self.iupacdna_alphabet)\n",
    "        if len(stripped) > 0:\n",
    "            raise ValueError(\"Non-IUPAC DNA char found: '\" + stripped[0] +\"'\")\n",
    "        \n",
    "        complemented = self.sequence[::-1].translate(self.complementtable)\n",
    "        \n",
    "        return FastaEntry(self.header, complemented)\n",
    "    \n",
    "    def check(self, alphabet):\n",
    "        \"\"\"This is not done at instantiation because it takes time.\"\"\"\n",
    "        \n",
    "        if alphabet not in (FastaEntry.dna_alphabet, FastaEntry.rna_alphabet,\n",
    "                            FastaEntry.aa_alphabet, FastaEntry.iupacdna_alphabet):\n",
    "            \n",
    "            raise ValueError(('Only accepts dna_alphabet, iupacdna_alphabet,'\n",
    "                              'rna_alphabet or aa_alphabet of the FastaEntry class'))\n",
    "            \n",
    "        # Check if any characters survives removal of entire alphabet\n",
    "        stripped = self.sequence.translate(None, delete=alphabet)\n",
    "        if len(stripped) > 0:\n",
    "            raise ValueError(\"Invalid character found: '\" + chr(stripped[0]) + \"'\")\n",
    "    \n",
    "    def translated(self, endatstop=True):\n",
    "        codons = zip(*[iter(self.sequence)] * 3)\n",
    "        try:\n",
    "            translated_bytes = [self.genetic_code.get(codon) for codon in codons]\n",
    "            translated = bytearray(translated_bytes)\n",
    "        except KeyError as exception:\n",
    "            exception.args = (f'{exception.args[0]} is not a valid DNA codon',)\n",
    "            raise\n",
    "        \n",
    "        if endatstop:\n",
    "            stoppos = translated.find(42)\n",
    "            if stoppos == 0:\n",
    "                return None\n",
    "            \n",
    "            elif stoppos != -1:\n",
    "                translated = translated[:stoppos]\n",
    "                \n",
    "        return FastaEntry(self.header, translated)\n",
    "    \n",
    "    def kmercounts(self, k):\n",
    "        if k < 1 or k > 10:\n",
    "            raise ValueError('k must be between 1 and 10 inclusive')\n",
    "        return _kmercounts(self.sequence, k)\n",
    "    \n",
    "    def fourmer_freq(self):\n",
    "        return _fourmerfreq(self.sequence)\n",
    "    \n",
    "    def threemer_freq(self):\n",
    "        return _threemerfreq(self.sequence)\n",
    "    \n",
    "    def freq_432mers(self):\n",
    "        return _freq_432mers(self.sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterfasta(filehandle, alphabet=None, comment='#'):\n",
    "    \"\"\"A generator which yields FastaEntries from an open fasta file.\n",
    "    \n",
    "    Usage:\n",
    "    >>> with open('myfile.fasta') as fastafile:\n",
    "    ...     entries = iterfasta(fastafile)\n",
    "    ...\n",
    "    ...     for entry in entries:\n",
    "    ...         [ DO STUFF ]\n",
    "    \"\"\"\n",
    "    \n",
    "    if alphabet is not None:\n",
    "        if alphabet not in (FastaEntry.dna_alphabet, FastaEntry.rna_alphabet,\n",
    "                            FastaEntry.aa_alphabet, FastaEntry.iupacdna_alphabet):\n",
    "            \n",
    "            raise ValueError(('Only accepts dna_alphabet, iupacdna_alphabet,'\n",
    "                              'rna_alphabet or aa_alphabet of the FastaEntry class'))\n",
    "    \n",
    "    # Skip to first header\n",
    "    for linenumber, probeline in enumerate(filehandle):\n",
    "        stripped = probeline.lstrip()\n",
    "        if stripped.startswith(comment):\n",
    "            pass\n",
    "\n",
    "        elif probeline[0] == '>':\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            raise TypeError('First non-comment line is not a Fasta header')\n",
    "\n",
    "    else: # nobreak\n",
    "        raise TypeError('Empty or outcommented file')\n",
    "    \n",
    "    header = probeline[1:-1]\n",
    "    buffer = list()\n",
    "    \n",
    "    # Iterate over lines\n",
    "    for line in map(str.rstrip, filehandle):\n",
    "        linenumber += 1\n",
    "        \n",
    "        # If line is header, yield the last sequence\n",
    "        if line[0] == '>':\n",
    "            yield FastaEntry(header, b''.join(buffer))\n",
    "            buffer.clear()\n",
    "            header = line[1:]\n",
    "        \n",
    "        # Else check the line and add it to current sequence\n",
    "        else:\n",
    "            byteline = line.encode()\n",
    "            \n",
    "            if alphabet is not None:\n",
    "                stripped = byteline.translate(None, delete=alphabet)\n",
    "                if len(stripped) > 0:\n",
    "                    raise ValueError(f\"Line {linenumber + 1}: Invalid character found: '\" +\n",
    "                                     chr(stripped[0]) +\"'\")\n",
    "\n",
    "            buffer.append(byteline)\n",
    "            \n",
    "    yield FastaEntry(header, b''.join(buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_iterfasta(filehandle):\n",
    "    \"\"\"Yields (header, sequence) tuples from an open fasta file.\n",
    "    \n",
    "    Usage:\n",
    "    >>> with open('myfile.fasta') as fastafile:\n",
    "    ...     entries = iterfasta(fastafile)\n",
    "    ...\n",
    "    ...     for entry in entries:\n",
    "    ...         [ DO STUFF ]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Skip to first header\n",
    "    for probeline in filehandle:\n",
    "        if probeline.startswith('>'):\n",
    "            break\n",
    "    else: # nobreak\n",
    "        raise ValueError('No headers in this file.')\n",
    "    \n",
    "    header = probeline.strip('>\\n')\n",
    "    buffer = list()\n",
    "    \n",
    "    # Iterate over lines\n",
    "    for line in map(str.rstrip, filehandle):\n",
    "        if line.startswith('>'): \n",
    "            yield header, ''.join(buffer)\n",
    "            buffer.clear()\n",
    "            header = line[1:]\n",
    "            \n",
    "        else:\n",
    "            buffer.append(line)\n",
    "            \n",
    "    yield header, ''.join(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AssemblyStats = _collections.namedtuple('AssemblyStats', ['size', 'n50', 'ncontigs', 'largest', 'smallest', 'sizemax', 'sizestep', 'sizes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemblystats(fasta_path, xmax=10000, step=100):\n",
    "    \"\"\"Returns statistics about a fasta file from an assembly.\"\"\"\n",
    "    \n",
    "    length_counter = _collections.Counter()\n",
    "    \n",
    "    with open(fasta_path) as filehandle:\n",
    "        for header, sequence in simple_iterfasta(filehandle):\n",
    "            length_counter[len(sequence)] += 1\n",
    "    \n",
    "    lengthcounts = sorted(length_counter.items(), reverse=True)\n",
    "    \n",
    "    # Initialize and calculate all other variables than \"lengths\" and \"N50\"\n",
    "    assemblysize = sum(length * count for length, count in lengthcounts)\n",
    "    ncontigs = sum(count for length, count in lengthcounts)\n",
    "    largestcontig = lengthcounts[0][0]\n",
    "    smallestcontig = lengthcounts[-1][0]\n",
    "    N50 = None\n",
    "    \n",
    "    # Length distribution\n",
    "    lengths = list()\n",
    "    thresholds = reversed(range(0, xmax + 1, step))\n",
    "    threshold = next(thresholds)\n",
    "    currentsize = 0\n",
    "    \n",
    "    for length, count in lengthcounts:\n",
    "        while length < threshold:\n",
    "            lengths.append(currentsize)\n",
    "            threshold = next(thresholds)\n",
    "            \n",
    "        currentsize += length * count\n",
    "        \n",
    "        if N50 is None and currentsize >= assemblysize/2:\n",
    "            N50 = length\n",
    "    \n",
    "    lengths.append(currentsize)\n",
    "    for threshold in thresholds:\n",
    "        lengths.append(currentsize)\n",
    "    \n",
    "    lengths = lengths[::-1]\n",
    "            \n",
    "    return AssemblyStats(assemblysize, N50, ncontigs, largestcontig, smallestcontig, xmax, step, lengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
