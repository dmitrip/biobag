{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'======================== JAKOBS CANOPY PARSER SCRIPT ======================\\nParses a canopy clusters file and a corresponding gene catalogue.\\nOutputs a directory with each of the bins as fasta file and/or a \"query\" amino\\nacid fasta file with all the genes present in any cluster.\\n\\nAll sequences are stored in memory, you so might want to give it a couple of GB\\nto work with.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Parses a canopy clusters file and a corresponding gene catalogue.\n",
    "Outputs a directory with each of the bins as fasta file and/or a \"query\" amino\n",
    "acid fasta file with all the genes present in any cluster.\n",
    "\n",
    "All sequences are stored in memory, you so might want to give it a couple of GB\n",
    "to work with.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jakob Nybo Nissen, DTU Bioinformatics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genetic_code = {\n",
    "    ('A', 'A', 'A'): 'K', ('A', 'A', 'G'): 'K', ('A', 'A', 'T'): 'N', ('A', 'A', 'C'): 'N', \n",
    "    ('A', 'G', 'A'): 'R', ('A', 'G', 'G'): 'R', ('A', 'G', 'T'): 'S', ('A', 'G', 'C'): 'S', \n",
    "    ('A', 'T', 'A'): 'I', ('A', 'T', 'G'): 'M', ('A', 'T', 'T'): 'I', ('A', 'T', 'C'): 'I', \n",
    "    ('A', 'C', 'A'): 'T', ('A', 'C', 'G'): 'T', ('A', 'C', 'T'): 'T', ('A', 'C', 'C'): 'T', \n",
    "    ('G', 'A', 'A'): 'E', ('G', 'A', 'G'): 'E', ('G', 'A', 'T'): 'D', ('G', 'A', 'C'): 'D', \n",
    "    ('G', 'G', 'A'): 'G', ('G', 'G', 'G'): 'G', ('G', 'G', 'T'): 'G', ('G', 'G', 'C'): 'G', \n",
    "    ('G', 'T', 'A'): 'V', ('G', 'T', 'G'): 'V', ('G', 'T', 'T'): 'V', ('G', 'T', 'C'): 'V', \n",
    "    ('G', 'C', 'A'): 'A', ('G', 'C', 'G'): 'A', ('G', 'C', 'T'): 'A', ('G', 'C', 'C'): 'A', \n",
    "    ('T', 'A', 'A'):  '', ('T', 'A', 'G'):  '', ('T', 'A', 'T'): 'Y', ('T', 'A', 'C'): 'Y', \n",
    "    ('T', 'G', 'A'):  '', ('T', 'G', 'G'): 'W', ('T', 'G', 'T'): 'C', ('T', 'G', 'C'): 'C', \n",
    "    ('T', 'T', 'A'): 'L', ('T', 'T', 'G'): 'L', ('T', 'T', 'T'): 'F', ('T', 'T', 'C'): 'F', \n",
    "    ('T', 'C', 'A'): 'S', ('T', 'C', 'G'): 'S', ('T', 'C', 'T'): 'S', ('T', 'C', 'C'): 'S', \n",
    "    ('C', 'A', 'A'): 'Q', ('C', 'A', 'G'): 'Q', ('C', 'A', 'T'): 'H', ('C', 'A', 'C'): 'H', \n",
    "    ('C', 'G', 'A'): 'R', ('C', 'G', 'G'): 'R', ('C', 'G', 'T'): 'R', ('C', 'G', 'C'): 'R', \n",
    "    ('C', 'T', 'A'): 'L', ('C', 'T', 'G'): 'L', ('C', 'T', 'T'): 'L', ('C', 'T', 'C'): 'L', \n",
    "    ('C', 'C', 'A'): 'P', ('C', 'C', 'G'): 'P', ('C', 'C', 'T'): 'P', ('C', 'C', 'C'): 'P', \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdir(name, indent=False):\n",
    "    \"\"\"Creates a new directory in a threadsafe way.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(name)\n",
    "    except FileExistsError:\n",
    "        if os.path.isfile(name):\n",
    "            raise\n",
    "        print('\\t'*indent + 'Directory {} already exists, skipping creation.'.format(name))\n",
    "    else:\n",
    "        print('\\t'*indent + 'Creating directory \"{}\".'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timed(function):\n",
    "    \"\"\"Decorator adding a timer to a function,\n",
    "    and prints the time elapsed in the terminal. Just eye candy.\"\"\"\n",
    "    \n",
    "    def inner(*args, **kwargs):\n",
    "        begin = time()\n",
    "        result = function(*args, **kwargs)\n",
    "        print('\\tDone in {:,.2f} seconds'.format(time() - begin))\n",
    "        return result\n",
    "    \n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterfasta(filehandle):\n",
    "    \"Iterate over a fasta file, yielding (first_word_inheader, seq) tuples\"\n",
    "    \n",
    "    buffer = list()\n",
    "    \n",
    "    header = next(filehandle).strip()\n",
    "    if not header.startswith('>'):\n",
    "        raise ValueError('First line is not a header')\n",
    "    header = header.split()[0][1:]\n",
    "    \n",
    "    for line in map(str.strip, filehandle):\n",
    "        if line.startswith('>'): \n",
    "            yield header, ''.join(buffer)\n",
    "            buffer.clear()\n",
    "            header = line.split()[0][1:]\n",
    "            \n",
    "        else:\n",
    "            buffer.append(line)\n",
    "\n",
    "    yield header, ''.join(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timed\n",
    "def translatedict(seqdict, code=genetic_code):\n",
    "    print('Translating sequence dictionary.')\n",
    "    \n",
    "    if args.progress:\n",
    "        status = '\\t{{}}/{} k sequences translated.'.format(len(seqdict)//1000)\n",
    "        for n, (name, sequence) in enumerate(seqdict.items()):\n",
    "            if n % 1000 == 0:\n",
    "                print(status.format(n//1000), end='\\r')\n",
    "            seqdict[name] = ''.join([code.get(codon, 'X') for codon in zip(*[iter(sequence)]*3)])\n",
    "        \n",
    "        print(' '*70, end='\\r') # clear output line\n",
    "    \n",
    "    else:\n",
    "        for name, sequence in seqdict.items():\n",
    "            seqdict[name] = ''.join([code.get(codon, 'X') for codon in zip(*[iter(sequence)]*3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timed\n",
    "def init_dicts(mingenes, clusterspath):\n",
    "    \"\"\"Reads a canopy cluster file and initializes two dicts:\n",
    "    bindict: a binname:[genes] dict\n",
    "    seqdict: a name:seq dict\n",
    "    \"\"\"\n",
    "    \n",
    "    print('Parsing clusters.')\n",
    "\n",
    "    seqdict = dict()\n",
    "    bindict = defaultdict(list)\n",
    "    \n",
    "    with open(clusterspath) as file:\n",
    "        currentbin, gene = next(file).split()\n",
    "        currentbinbuffer = [(currentbin, gene)]\n",
    "        \n",
    "        for bin, gene in map(str.split, file):\n",
    "            if bin != currentbin:\n",
    "                \n",
    "                if len(currentbinbuffer) >= mingenes:\n",
    "                    for bufbin, bufgene in currentbinbuffer:\n",
    "                        seqdict[bufgene] = None\n",
    "                        bindict[bufbin].append(bufgene)\n",
    "                \n",
    "                currentbinbuffer.clear()\n",
    "                currentbin = bin\n",
    "            \n",
    "            currentbinbuffer.append((bin, gene))\n",
    "        \n",
    "        for bufbin, bufgene in currentbinbuffer:\n",
    "            seqdict[bufgene] = None\n",
    "            bindict[bufbin].append(bufgene)\n",
    "\n",
    "    return bindict, seqdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timed\n",
    "def fill_seqdict(seqdict, cataloguein, as_aa=False, code=genetic_code):\n",
    "    \"Fills the seqdict from a gene catalogue.\"\n",
    "    \n",
    "    progress = args.progress\n",
    "    print('Filling in genes from gene catalogue.')\n",
    "    \n",
    "    # Parsing gene catalogue\n",
    "    with open(cataloguein) as inputfile:\n",
    "        for n, (name, sequence) in enumerate(iterfasta(inputfile)):\n",
    "            if progress and n % 1000 == 0:\n",
    "                print('\\tProcessed {}k genes.'.format(n//1000), end='\\r')\n",
    "                \n",
    "            if name in seqdict:\n",
    "                if as_aa:\n",
    "                    seqdict[name] = ''.join([code.get(codon, 'X') for codon in zip(*[iter(sequence)]*3)])\n",
    "                else:\n",
    "                    seqdict[name] = sequence\n",
    "                \n",
    "    if progress:\n",
    "        print(' '*50, end='\\r') # clear the line\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timed\n",
    "def write_bins(bindict, seqdict, bindir):\n",
    "    \"Given a bindict and a filled seqdict, writes nucleotide gene bins\"\n",
    "    \n",
    "    progress = args.progress\n",
    "    print('Creating bins.')\n",
    "    mkdir(bindir, indent=True)\n",
    "        \n",
    "    # Check which files exist:\n",
    "    presentfiles = [i.name for i in os.scandir(bindir)]\n",
    "    missingfiles = [name+'.fna' for name in bindict if name+'.fna' not in presentfiles]\n",
    "    \n",
    "    if progress:\n",
    "        status = '\\tCreated {{}}/{} MGSs'.format(len(missingfiles))\n",
    "    \n",
    "    if not missingfiles:\n",
    "        print('\\tAll files already exists. Skipping creation.')\n",
    "        return\n",
    "    elif len(missingfiles) != len(bindict):\n",
    "        nexist = len(bindict) - len(missingfiles)\n",
    "        print('\\t{} files already exist. Creating rest.'.format(nexist))\n",
    "    \n",
    "    buffer = list()\n",
    "    \n",
    "    for processed, filename in enumerate(missingfiles):\n",
    "        for gene in bindict[filename[:-4]]:\n",
    "            buffer.append('>{}\\n{}'.format(gene, seqdict[gene]))\n",
    "        \n",
    "        fullname = os.path.join(bindir, filename)\n",
    "        with open(fullname, 'w') as file:\n",
    "            print('\\n'.join(buffer), file=file)\n",
    "        \n",
    "        buffer.clear()\n",
    "        if progress:\n",
    "            print(status.format(processed), end='\\r')\n",
    "    \n",
    "    if progress:\n",
    "        print(' '*50, end='\\r') # clear line\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timed\n",
    "def write_query(seqdict, queryout):\n",
    "    \"\"\"Given a filled seqdict, writes the query.\"\"\"\n",
    "    \n",
    "    print('Creating amino acid query file.')\n",
    "    \n",
    "    buffer = list()\n",
    "    \n",
    "    with open(queryout, 'w') as query:\n",
    "        for gene, sequence in seqdict.items():\n",
    "            buffer.append('>{}\\n{}'.format(gene, sequence))\n",
    "            \n",
    "            if len(buffer) == 10000:\n",
    "                print('\\n'.join(buffer), file=query)\n",
    "                buffer.clear()\n",
    "        \n",
    "        print('\\n'.join(buffer), file=query)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(args, code=genetic_code):\n",
    "    \"\"\"Execute the entire workflow of this script.\"\"\"\n",
    "    \n",
    "    begin_time = time()\n",
    "    \n",
    "    # In all cases, init the dicts\n",
    "    bindict, seqdict = init_dicts(args.mingenes, args.clusters)\n",
    "    \n",
    "    # If bins are desired, construct directory, then load as NT, then convert\n",
    "    if args.bindir is not None:\n",
    "        fill_seqdict(seqdict, args.cataloguein, as_aa=False)\n",
    "        write_bins(bindict, seqdict, args.bindir)\n",
    "    \n",
    "    # If query is desired\n",
    "    if args.queryout is not None:\n",
    "        # If bins have been created, seqdict has been created, must be translated\n",
    "        if args.bindir is not None:\n",
    "            translatedict(seqdict)\n",
    "        \n",
    "        # Else, fill it directly with amino acids\n",
    "        else:\n",
    "            fill_seqdict(seqdict, args.cataloguein, as_aa=True)\n",
    "\n",
    "        write_query(seqdict, args.queryout)\n",
    "        \n",
    "    print('Complete. Total elapsed time:', round(time() - begin_time, 2), 'seconds.')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Arg parsing, checking necessary files etc\n",
    "if __name__ == '__main__':\n",
    "    usage = 'python parsecanopy.py clusters catalogue [-q query] [-b bindir] [options]'\n",
    "    \n",
    "    # Parse input\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=__doc__,\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        usage=usage)\n",
    "    \n",
    "    # Required, positional arguments\n",
    "    parser.add_argument('clusters', help='Canopy clusters path',\n",
    "                        metavar='clusters')\n",
    "    parser.add_argument('cataloguein', help='path to gene catalogue',\n",
    "                        metavar='catalogue')\n",
    "    \n",
    "    outputgroup = parser.add_argument_group('output')\n",
    "    outputgroup.add_argument('-q', dest='queryout', help='path to write query to',\n",
    "                            metavar='query')\n",
    "    outputgroup.add_argument('-b', dest='bindir', help='directory to write bins to',\n",
    "                            metavar='bindir')\n",
    "    \n",
    "    parser.add_argument('-m', dest='mingenes', type=int, default=1, metavar='mingenes',\n",
    "                        help='minimum size of genes per cluster [1]')\n",
    "    parser.add_argument('--progress', action='store_true',\n",
    "        help='Print progress continually to stdout [False]')\n",
    "    \n",
    "    # Invoke help if called with no argument\n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help()\n",
    "        sys.exit()\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Must state either make bins or query\n",
    "    if not (args.queryout or args.bindir):\n",
    "        raise ValueError('Must make either bins or query file.')\n",
    "    \n",
    "    # Input files must actually exist\n",
    "    for path in (args.clusters, args.cataloguein):\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(path)\n",
    "            \n",
    "    if args.queryout is not None and os.path.exists(args.queryout):\n",
    "        raise FileExistsError(args.queryout)\n",
    "        \n",
    "    if args.bindir is not None and os.path.isfile(args.bindir):\n",
    "        raise FileExistsError('{} is a regular existing file.'.format(args.queryout))\n",
    "        \n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
