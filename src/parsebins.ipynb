{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Parses a directory of bins, either of contigs or DNA genes. If former, creates\n",
    "a directory of gene bins. In either case, then parses the gene bins, and\n",
    "optionally writes two files:\n",
    "1) a \"query\" amino acid fasta file with all the genes present in any cluster.\n",
    "2) A \"bin table\" - a table of the content of each bin for quick parsing later.\n",
    "\n",
    "Contigs with same first word in the header are considered identical. Beware.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'Jakob Nybo Nissen, DTU Bioinformatics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "from time import time\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genetic_code = {\n",
    "    ('A', 'A', 'A'): 'K', ('A', 'A', 'G'): 'K', ('A', 'A', 'T'): 'N', ('A', 'A', 'C'): 'N', \n",
    "    ('A', 'G', 'A'): 'R', ('A', 'G', 'G'): 'R', ('A', 'G', 'T'): 'S', ('A', 'G', 'C'): 'S', \n",
    "    ('A', 'T', 'A'): 'I', ('A', 'T', 'G'): 'M', ('A', 'T', 'T'): 'I', ('A', 'T', 'C'): 'I', \n",
    "    ('A', 'C', 'A'): 'T', ('A', 'C', 'G'): 'T', ('A', 'C', 'T'): 'T', ('A', 'C', 'C'): 'T', \n",
    "    ('G', 'A', 'A'): 'E', ('G', 'A', 'G'): 'E', ('G', 'A', 'T'): 'D', ('G', 'A', 'C'): 'D', \n",
    "    ('G', 'G', 'A'): 'G', ('G', 'G', 'G'): 'G', ('G', 'G', 'T'): 'G', ('G', 'G', 'C'): 'G', \n",
    "    ('G', 'T', 'A'): 'V', ('G', 'T', 'G'): 'V', ('G', 'T', 'T'): 'V', ('G', 'T', 'C'): 'V', \n",
    "    ('G', 'C', 'A'): 'A', ('G', 'C', 'G'): 'A', ('G', 'C', 'T'): 'A', ('G', 'C', 'C'): 'A', \n",
    "    ('T', 'A', 'A'):  '', ('T', 'A', 'G'):  '', ('T', 'A', 'T'): 'Y', ('T', 'A', 'C'): 'Y', \n",
    "    ('T', 'G', 'A'):  '', ('T', 'G', 'G'): 'W', ('T', 'G', 'T'): 'C', ('T', 'G', 'C'): 'C', \n",
    "    ('T', 'T', 'A'): 'L', ('T', 'T', 'G'): 'L', ('T', 'T', 'T'): 'F', ('T', 'T', 'C'): 'F', \n",
    "    ('T', 'C', 'A'): 'S', ('T', 'C', 'G'): 'S', ('T', 'C', 'T'): 'S', ('T', 'C', 'C'): 'S', \n",
    "    ('C', 'A', 'A'): 'Q', ('C', 'A', 'G'): 'Q', ('C', 'A', 'T'): 'H', ('C', 'A', 'C'): 'H', \n",
    "    ('C', 'G', 'A'): 'R', ('C', 'G', 'G'): 'R', ('C', 'G', 'T'): 'R', ('C', 'G', 'C'): 'R', \n",
    "    ('C', 'T', 'A'): 'L', ('C', 'T', 'G'): 'L', ('C', 'T', 'T'): 'L', ('C', 'T', 'C'): 'L', \n",
    "    ('C', 'C', 'A'): 'P', ('C', 'C', 'G'): 'P', ('C', 'C', 'T'): 'P', ('C', 'C', 'C'): 'P', \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mkdir(name, indent=False):\n",
    "    \"\"\"Creates a new directory in a threadsafe way.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(name)\n",
    "    except FileExistsError:\n",
    "        if os.path.isfile(name):\n",
    "            raise\n",
    "        print('\\t'*indent + 'Directory {} already exists, skipping creation.'.format(name))\n",
    "    else:\n",
    "        print('\\t'*indent + 'Creating directory \"{}\".'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timed(function):\n",
    "    \"\"\"Decorator adding a timer to a function,\n",
    "    and prints the time elapsed in the terminal. Just eye candy.\"\"\"\n",
    "    \n",
    "    def inner(*args, **kwargs):\n",
    "        begin = time()\n",
    "        result = function(*args, **kwargs)\n",
    "        print('\\tDone in {:,.2f} seconds'.format(time() - begin))\n",
    "        return result\n",
    "    \n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterfasta(filehandle):\n",
    "    \"Iterate over a fasta file, yielding (first word in header, seq) tuples\"\n",
    "    \n",
    "    buffer = list()\n",
    "    \n",
    "    header = next(filehandle).strip()\n",
    "    if not header.startswith('>'):\n",
    "        raise ValueError('First line is not a header')\n",
    "    header = header.split()[0][1:]\n",
    "    \n",
    "    for line in map(str.strip, filehandle):\n",
    "        if line.startswith('>'): \n",
    "            yield header, ''.join(buffer)\n",
    "            buffer.clear()\n",
    "            header = line.split()[0][1:]\n",
    "            \n",
    "        else:\n",
    "            buffer.append(line)\n",
    "\n",
    "    yield header, ''.join(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def callshell(command):\n",
    "    \"Calls the shell. Must be a top-level function to be parallelizable.\"\n",
    "    \n",
    "    return subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timed\n",
    "def makebins(contigdir, bindir, extension):\n",
    "    \"Runs prodigal on each of the bins in parallel.\"\n",
    "    \n",
    "    mkdir(args.bindir)\n",
    "    mkdir(args.logdir)\n",
    "    \n",
    "    # Get all files to process:\n",
    "    infiles = [i.name for i in os.scandir(contigdir) if i.is_file()]\n",
    "    filenames = [f.rpartition('.')[0] for f in infiles]\n",
    "    \n",
    "    infiles = [os.path.join(contigdir, f) for f in infiles if f.endswith(extension)]\n",
    "    outfiles = [os.path.join(bindir, n + '.fna') for n in filenames]\n",
    "    \n",
    "    exist = [os.path.exists(f) for f in outfiles]\n",
    "    infiles = [f for f, exists in zip(infiles, exist) if not exists]\n",
    "    outfiles = [f for f, exists in zip(outfiles, exist) if not exists]\n",
    "    filenames = [f for f, exists in zip(filenames, exist) if not exists]\n",
    "\n",
    "    if not outfiles:\n",
    "        print('All aa files already exists, skipping creation...')\n",
    "        return\n",
    "    elif len(outfiles) != len(exist):\n",
    "        print('{}/{} aa files already exists, creating rest.'.format(\n",
    "              len(exist) - len(outfiles), len(exist)))\n",
    "    else:\n",
    "        print('Creating aa files with prodigal ({} cores).'.format(args.cores))\n",
    "    \n",
    "    # Create a list of the commands to be executed in shell\n",
    "    template = '{exec} -p meta -i {infile} -d {outpath} > {stdout} 2> {stderr}'\n",
    "    commands = list()\n",
    "    \n",
    "    for filename, infile, outfile in zip(filenames, infiles, outfiles):\n",
    "        stdout = '{}/prodigal.{}.stdout'.format(args.logdir, filename)\n",
    "        stderr = '{}/prodigal.{}.stderr'.format(args.logdir, filename)\n",
    "        commands.append(template.format(exec=args.prodigalpath,\n",
    "                                        infile=infile, outpath=outfile,\n",
    "                                        stdout=stdout, stderr=stderr))\n",
    "    \n",
    "    # Execute prodigal in parallel\n",
    "    if args.progress:\n",
    "        processes_done = 0\n",
    "        \n",
    "        def callback(result, totalps=len(outfiles)):\n",
    "            \"Generator yielding processed\"\n",
    "            nonlocal processes_done\n",
    "            processes_done += 1\n",
    "            end = '\\n' if processes_done == totalps else '\\r'\n",
    "            print('\\tBins processed: {}/{}'.format(processes_done, totalps), end=end)\n",
    "            return None\n",
    "    else:\n",
    "        def callback(result):\n",
    "            pass\n",
    "\n",
    "    results = list()\n",
    "    with multiprocessing.Pool(processes=args.cores) as pool:\n",
    "        for command in commands:\n",
    "            results.append(pool.apply_async(callshell, (command,),\n",
    "                                            callback=callback, error_callback=callback))\n",
    "        \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    \n",
    "    for result in results:\n",
    "        if not result.successful():\n",
    "            print('One or more prodigal processed failed.')    \n",
    "            result.get() # raise its error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timed\n",
    "def makequery(bindir, queryout, extension, code=genetic_code):\n",
    "    \"Creates the query file from the gene bins and returns a dict of bins.\"\n",
    "    \n",
    "    print('Parsing bins and creating query file.')\n",
    "    progress = args.progress\n",
    "    \n",
    "    bindict = defaultdict(list)\n",
    "    seengenes = set()\n",
    "    buffer = list()\n",
    "    \n",
    "    # Get the files with the right extension\n",
    "    infiles = [os.path.join(bindir, i.name) for i in os.scandir(bindir)\n",
    "               if i.is_file() and i.name.endswith('.' + extension)]\n",
    "    print('\\tFound {} files with extension {}.'.format(len(infiles), extension))\n",
    "    \n",
    "    with open(queryout, 'w') as queryfile:\n",
    "        # Iterate over the input file, construct bindir and queryfile\n",
    "        for n, infile in enumerate(infiles):\n",
    "            basename = os.path.basename(infile).rpartition('.')[0]\n",
    "\n",
    "            with open(infile) as file:\n",
    "                for name, sequence in iterfasta(file):\n",
    "                    bindict[basename].append(name)\n",
    "\n",
    "                    if name not in seengenes:\n",
    "                        seengenes.add(name)\n",
    "                        translated = ''.join([code.get(codon, 'X') for codon in zip(*[iter(sequence)]*3)])\n",
    "                        buffer.append('>{}\\n{}'.format(name, translated))\n",
    "\n",
    "                        if len(buffer) == 10000:\n",
    "                            print('\\n'.join(buffer), file=queryfile)\n",
    "                            buffer.clear()\n",
    "\n",
    "            if progress:\n",
    "                print('\\t{}/{} bins processed.'.format(n, len(infiles)), end='\\r')\n",
    "\n",
    "        print('\\n'.join(buffer), file=queryfile)\n",
    "        \n",
    "    if progress:\n",
    "        print(' '*70, end='\\r')\n",
    "    \n",
    "    return bindict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timed\n",
    "def makebintable(bindict, bintableout):\n",
    "    \"Create the bin table from the dictionary returned by makequery.\"\n",
    "    \n",
    "    print('Creating clusters file.')\n",
    "    \n",
    "    buffer = list()\n",
    "    \n",
    "    for bin, genes in bindict.items():\n",
    "        separator = '\\n' + bin + '\\t'\n",
    "        buffer.append(bin + '\\t')\n",
    "        buffer.append(separator.join(genes))\n",
    "        buffer.append('\\n')\n",
    "    \n",
    "    with open(bintableout, 'w') as clustersfile:\n",
    "        print(''.join(buffer), file=clustersfile, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \"Executes the entire workflow of this script.\"\n",
    "    \n",
    "    begin_time = time()\n",
    "    # First call prodigal\n",
    "    if args.contigdir is not None:\n",
    "        makebins(args.contigdir, args.bindir, args.extension)\n",
    "    \n",
    "    # If query is chosen, create that. Extension is .fna when bins are created\n",
    "    # by makebins, else user-set extension.\n",
    "    if args.queryout is not None:\n",
    "        if args.contigdir is not None:\n",
    "            extension = 'fna'\n",
    "        else:\n",
    "            extension = args.extension\n",
    "            \n",
    "        bindict = makequery(args.bindir, args.queryout, extension)\n",
    "        makebintable(bindict, args.bintableout)\n",
    "    print('Complete. Total elapsed time:', round(time() - begin_time, 2), 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Command line parsing\n",
    "if __name__ == '__main__':\n",
    "    usage = \"python parsebins.py bindir [contigdir] [-q query -b bintable] [options]\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=__doc__,\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        usage=usage)\n",
    "    \n",
    "    cpus = os.cpu_count()\n",
    "    \n",
    "    # Positional arguments\n",
    "    parser.add_argument('bindir', help='directory to find/write gene bins')\n",
    "    parser.add_argument('contigdir', nargs='?', help='path to bins of contigs (optional)')\n",
    "    \n",
    "    # For creation of bin table and query\n",
    "    bintablegroup = parser.add_argument_group('Query and bintable')\n",
    "    bintablegroup.add_argument('-q', dest='queryout', metavar='query',\n",
    "                               help='path to write query to')\n",
    "    bintablegroup.add_argument('-b', dest='bintableout', metavar='bintable',\n",
    "                               help='path to write list of bins')\n",
    "    \n",
    "    # Optional arguments\n",
    "    parser.add_argument('-e', dest='extension', default=\"fna\", metavar='extension',\n",
    "                        help='extension of input bins [fna]')\n",
    "    parser.add_argument('-p', dest='prodigalpath', metavar='prodigal',\n",
    "                        default='/services/tools/prodigal/2.6.3/prodigal',\n",
    "                        help='path to prodigal executable [preset]')\n",
    "    parser.add_argument('-c', dest='cores', type=int, default=cpus, metavar='cores',\n",
    "        help='no. of parallel prodigal jobs [{}]'.format(cpus))\n",
    "    parser.add_argument('--progress', action='store_true',\n",
    "        help='print progress continually to stdout [False]')\n",
    "\n",
    "    # If no arguments, print help\n",
    "    if len(sys.argv) == 1:\n",
    "        parser.print_help()\n",
    "        sys.exit()\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Check number of cores\n",
    "    if args.cores < 1:\n",
    "        raise argsparse.ArgumentTypeError('Zero or negative cores provided. Exiting')\n",
    "        \n",
    "    # You must state either contigdir or queryout\n",
    "    if args.contigdir is None and args.queryout is None:\n",
    "        raise ValueError('Input is gene bins, no output specified.')\n",
    "        \n",
    "    # If you state query or bintableout, you must also state the other\n",
    "    if bool(args.queryout) ^ bool(args.bintableout):\n",
    "        raise ValueError('query and bintable must be stated together.') \n",
    "        \n",
    "    # Prodigal executable must exist in filesystem if called upon\n",
    "    if args.contigdir is not None and not os.path.isfile(args.prodigalpath):\n",
    "        raise FileNotFoundError(args.prodigalpath)\n",
    "    \n",
    "    # Input directory must refer to an actual directory\n",
    "    if args.contigdir is None:\n",
    "        if not os.path.isdir(args.bindir):\n",
    "            raise FileNotFoundError('bindir: {}'.format(args.bindir))\n",
    "    else:\n",
    "        if not os.path.isdir(args.contigdir):\n",
    "            raise FileNotFoundError('contigdir: {}'.format(args.contigdir))\n",
    "    \n",
    "    # Output files must not exist\n",
    "    if args.queryout is not None and os.path.exists(args.queryout):\n",
    "        raise FileExistsError(args.queryout)\n",
    "        \n",
    "    if args.bintableout is not None and os.path.exists(args.bintableout):\n",
    "        raise FileExistsError(args.bintableout)\n",
    "        \n",
    "    # Make sure the log directory is not a file\n",
    "    args.logdir = os.path.join(args.bindir, 'prodigallog')\n",
    "    if args.contigdir is not None and os.path.isfile(args.logdir):\n",
    "        raise FileExistsError('File exists and is a regular file: {}'.format(args.logdir))\n",
    "\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
