{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misctools tutorial\n",
    "\n",
    "In my experience, bioinformaticians typically do highly situation-specific stuff to their data. So instead of providing a toolbox of tonnes of tools that'll never really apply anyway, I've so far simple made an easy-to-use API so you can patch together your own data analysis, UNIX-style.\n",
    "\n",
    "Obviously, the first stuff is to import the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import misctools as binf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasta sequences\n",
    "\n",
    "This simple example shows how to open and read a Fasta file, apply a filter and print to an output file.\n",
    "\n",
    "There's four lines:\n",
    "\n",
    "    with open('test.fasta') as fastafile, open('filtered.fasta', 'w') as outfile:\n",
    "        entries = binf.iterfasta(fastafile)\n",
    "        filtered = (entry for entry in entries if len(entry) >= 150) # generator expression!\n",
    "        binf.streamprint(filtered, outfile, buffersize=10000)\n",
    "\n",
    "1) First line opens an input fasta file and an output fasta file, keeping them open until the block is done.\n",
    "\n",
    "2) Second line creates an iterator of Fasta entries in the input file\n",
    "\n",
    "3) Third line creates a generator of filtered entries from the iterator in 2)\n",
    "\n",
    "4) Fourth line prints the content of the generator to the output file using a buffer\n",
    "\n",
    "Note the following properties:\n",
    "* Using the `with open` statement, the files automatically close if something goes wrong so that the operating system will not have them open indefinitely, which can lead to bad results\n",
    "* Before the fourth line, no data has been read. The iterator and generator are simply instructions about *how to process the data* once it's read \n",
    "* The streamprint function stores the output line in a buffer with a limited number of outputs. This strikes a balance between limiting disk access, which is slow, and keeping the output in memory, which may cause a big memory footprint\n",
    "* This code will be fast and memory efficient for files of all sizes: You can read a 100 GB file like this, using only a few MB of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more elaborate example\n",
    "\n",
    "Look through a fasta file for sequences from bacteria. All the ones with a name ending in an uneven number must be reverse complemented. Then translate to amino acids and truncate each of the sequences to before their first stop. Then write to a new file.\n",
    "\n",
    "No problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a generator of lines which does processing on the fly\n",
    "# Barely any memory footprint!\n",
    "def process():\n",
    "    with open('test.fasta') as fastafile:\n",
    "        entries = binf.iterfasta(fastafile)\n",
    "        \n",
    "        for entry in entries:\n",
    "            \n",
    "            # Skip non bacteria\n",
    "            if not 'Bacteria;' in entry.header:\n",
    "                continue\n",
    "            \n",
    "            # Reverse-complement the uneven ones\n",
    "            name = entry.header.split()[0]\n",
    "            if int(name[-1]) % 2 == 1:\n",
    "                entry.reversecomplement()\n",
    "                \n",
    "            entry = entry.translate(endatstop=True)\n",
    "            \n",
    "            # A sequence with only a stop codon will return None\n",
    "            if entry is not None:\n",
    "                yield entry\n",
    "                \n",
    "# Stream it to the output file\n",
    "with open('outfile', 'w') as outfile:\n",
    "    binf.streamprint(process(), outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastq files\n",
    "\n",
    "Fastq entries follow basically the same syntax.\n",
    "\n",
    "Note that since fastq files often have each entry over exactly four lines, one line per attribute, that can be exploited for speed. To do this, set singleline to True.\n",
    "\n",
    "Let's say we only want the ones where all the 10 last bases are less than 1 in 100 likely to be miscalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "maxlogprob = log(1/100)\n",
    "\n",
    "with open('test.fastq') as fastqfile:\n",
    "    entries = binf.iterfastq(fastqfile, singleline=True)\n",
    "    \n",
    "    # Check whether the reads make sense with a PHRED 33 score\n",
    "    goodentries = (entry for entry in entries if entry.check(phred=33))\n",
    "    \n",
    "    # Filter for the ones with good base calling probabilities\n",
    "    probable = (entry for entry in goodentries if max(entry.logprobs[-10:]) <= maxlogprob)\n",
    "    \n",
    "    # How many are there?\n",
    "    print(sum(1 for entry in probable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM files\n",
    "\n",
    "Python is much slower than compiled programs like samtools, so only iterate over SAM files if what you want cannot be achieved with samtools.\n",
    "\n",
    "For example, let's get all lines which are primary alignments where the partner does not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parse a SAM file and count how many headers there are, and how many lines with certain flags\n",
    "with open('test.sam') as samfile:\n",
    "    parser = binf.SamParser(samfile)\n",
    "    \n",
    "    print(sum(1 for header in parser.iterheaders()))\n",
    "    print(sum(1 for entry in parser if entry.hasflag('unmapped') and not entry.hasflag('partner unmapped')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
